///2024-01-22 14:15
Number of batches used for training 2000
Num Pairs: 10785
100%|██████████| 2000/2000 [03:02<00:00, 10.95it/s]
0.8104166666666667
Number of batches used for training 2000
Num Pairs: 9163
100%|██████████| 2000/2000 [02:59<00:00, 11.12it/s]
0.594170403587444
Number of batches used for training 2000
Num Pairs: 9962
100%|██████████| 2000/2000 [03:05<00:00, 10.80it/s]
0.5629522431259045
Number of batches used for training 2000
Num Pairs: 10450
100%|██████████| 2000/2000 [02:57<00:00, 11.28it/s]
0.7522441651705566
Number of batches used for training 2000
Num Pairs: 9556
100%|██████████| 2000/2000 [03:04<00:00, 10.86it/s]
0.6303797468354431
Performance on test data over 5 folds: 

0.670032645077203 +/- 0.10637204996915826
perf on each split was: [0.8104166666666667, 0.594170403587444, 0.5629522431259045, 0.7522441651705566, 0.6303797468354431] 

///2024-01-22 14:31
Number of batches used for training 2000
Num Pairs: 9612
100%|██████████| 2000/2000 [02:56<00:00, 11.33it/s]
0.7423076923076923
Number of batches used for training 2000
Num Pairs: 10391
100%|██████████| 2000/2000 [02:56<00:00, 11.32it/s]
0.6289198606271778
Number of batches used for training 2000
Num Pairs: 10102
100%|██████████| 2000/2000 [03:03<00:00, 10.90it/s]
0.5612403100775194
Number of batches used for training 2000
Num Pairs: 9824
100%|██████████| 2000/2000 [02:58<00:00, 11.23it/s]
0.5816186556927297
Number of batches used for training 2000
Num Pairs: 9800
100%|██████████| 2000/2000 [02:56<00:00, 11.30it/s]
0.7544581618655692
Performance on test data over 5 folds: 

0.6537089361141377 +/- 0.08994734526987616
perf on each split was: [0.7423076923076923, 0.6289198606271778, 0.5612403100775194, 0.5816186556927297, 0.7544581618655692]

///2024-01-22 14:49
Number of batches used for training 2000
Num Pairs: 10864
100%|██████████| 2000/2000 [03:10<00:00, 10.53it/s]
0.7388392857142857
Number of batches used for training 2000
Num Pairs: 9986
100%|██████████| 2000/2000 [03:07<00:00, 10.69it/s]
0.6735598227474151
Number of batches used for training 2000
Num Pairs: 10824
100%|██████████| 2000/2000 [03:08<00:00, 10.59it/s]
0.7297872340425532
Number of batches used for training 2000
Num Pairs: 10207
100%|██████████| 2000/2000 [03:03<00:00, 10.89it/s]
0.7420382165605095
Number of batches used for training 2000
Num Pairs: 10286
100%|██████████| 2000/2000 [03:10<00:00, 10.50it/s]
0.5179738562091504
Performance on test data over 5 folds: 

0.6804396830547828 +/- 0.09497703811950874
perf on each split was: [0.7388392857142857, 0.6735598227474151, 0.7297872340425532, 0.7420382165605095, 0.5179738562091504]

///2024-01-22 15:05
Number of batches used for training 2000
Num Pairs: 9617
100%|██████████| 2000/2000 [03:06<00:00, 10.71it/s]
0.7581453634085213
Number of batches used for training 2000
Num Pairs: 10431
100%|██████████| 2000/2000 [03:00<00:00, 11.06it/s]
0.7708333333333334
Number of batches used for training 2000
Num Pairs: 10636
100%|██████████| 2000/2000 [02:59<00:00, 11.17it/s]
0.5266272189349113
Number of batches used for training 2000
Num Pairs: 10122
100%|██████████| 2000/2000 [03:03<00:00, 10.88it/s]
0.5870570107858244
Number of batches used for training 2000
Num Pairs: 9872
100%|██████████| 2000/2000 [03:02<00:00, 10.98it/s]
0.5290055248618785
Performance on test data over 5 folds: 

0.6343336902648937 +/- 0.12133762172191673
perf on each split was: [0.7581453634085213, 0.7708333333333334, 0.5266272189349113, 0.5870570107858244, 0.5290055248618785]

///2024-01-22 15:21
Number of batches used for training 2000
Num Pairs: 10440
  0%|          | 0/2000 [00:00<?, ?it/s]
100%|██████████| 2000/2000 [03:05<00:00, 10.78it/s]
0.5776173285198556
Number of batches used for training 2000
Num Pairs: 10197
100%|██████████| 2000/2000 [03:02<00:00, 10.96it/s]
0.7288135593220338
Number of batches used for training 2000
Num Pairs: 10070
100%|██████████| 2000/2000 [03:06<00:00, 10.74it/s]
0.5626911314984709
Number of batches used for training 2000
Num Pairs: 10379
100%|██████████| 2000/2000 [03:09<00:00, 10.58it/s]
0.5041876046901173
Number of batches used for training 2000
Num Pairs: 9822
100%|██████████| 2000/2000 [03:14<00:00, 10.29it/s]
0.6844993141289437
Performance on test data over 5 folds: 

0.6115617876318843 +/- 0.09238187489128857
perf on each split was: [0.5776173285198556, 0.7288135593220338, 0.5626911314984709, 0.5041876046901173, 0.6844993141289437]

//2024-02-16 10:35 using CC

Performance on test data over 5 folds: 

0.6479850191958186 +/- 0.08928762546445285
perf on each split was: [0.6269727403156384, 0.7063197026022305, 0.5, 0.7066326530612245, 0.7]

// 2024-02-16 18:06 using res

Performance on test data over 5 folds: 

0.6202655384165696 +/- 0.06494523697159006
perf on each split was: [0.6216216216216216, 0.6159638554216867, 0.7235142118863049, 0.5460251046025104, 0.5942028985507246]

// 2024-04-07 19:19
Namespace(process=False, feature_set='SHUFFLE', fusion='GATED', omics_concat=False, lr=2e-05, weight_decay=0.005, batch_number=2000, omics_len=95, modelsummary=False, figure_dir='./figures', noplot=True)
*****
*****
Feature set: SHUFFLE
Node features: 1024
Graph path: ./data/graphs_shufflenet/
Pickle path: ./data/graphs_shufflenet_update/
*****
Preparing omics.
Getting tags.
Matching to omics.
NOW ON FOLD 1
*****
Number of batches used for training 2000
Num Pairs: 10016
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [03:08<00:00, 10.63it/s]
0.5973837209302325
NOW ON FOLD 2
*****
Number of batches used for training 2000
Num Pairs: 10806
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [03:04<00:00, 10.85it/s]
0.5995850622406639
NOW ON FOLD 3
*****
Number of batches used for training 2000
Num Pairs: 10325
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [03:06<00:00, 10.70it/s]
0.7495769881556683
NOW ON FOLD 4
*****
Number of batches used for training 2000
Num Pairs: 10285
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [03:05<00:00, 10.79it/s]
0.4636963696369637
NOW ON FOLD 5
*****
Number of batches used for training 2000
Num Pairs: 10066
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [03:01<00:00, 11.03it/s]
0.764179104477612
Performance on test data over 5 folds:
0.634884249088228 +/- 0.12432738666541064
perf on each split was: [0.5973837209302325, 0.5995850622406639, 0.7495769881556683, 0.4636963696369637, 0.764179104477612]

//2024-04-22 19:17 after new dataset
Performance on test data over 5 folds:
0.5673564086814115 +/- 0.11087598249494102
perf on each split was: [0.7505827505827506, 0.5155709342560554, 0.5679611650485437, 0.5471698113207547, 0.45549738219895286]